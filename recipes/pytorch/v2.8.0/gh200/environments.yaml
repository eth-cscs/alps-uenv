pytorch-env:
  compiler: [gcc]
  network:
      mpi: cray-mpich@8.1.32 +cuda
      specs:
      - libfabric@2.3 +gdrcopy +uring fabrics=cxi,rxm,sockets,tcp,udp,lnx
      - xpmem@2.9.6 ~kernel-module
  unify: true
  specs:
  - boost +chrono +filesystem +iostreams +mpi +python +regex +serialization +shared +system +timer
  - cmake
  - fftw
  - fmt
  - gsl
  - hdf5+cxx+hl+fortran
  - kokkos +aggressive_vectorization ~alloc_async cuda_arch=90 +cuda_constexpr +cuda_lambda ~cuda_relocatable_device_code ~cuda_uvm cxxstd=17 +openmp +pic +serial +shared +tuning +wrapper
  - kokkos-kernels +blas +cublas +cusparse +cusolver +execspace_cuda +execspace_openmp +execspace_serial +lapack +memspace_cudaspace +openmp scalars=float,double,complex_float,complex_double +serial +shared +     superlu
  - kokkos-tools +mpi +papi
  - netlib-scalapack
  - lua
  - libtree
  - lz4
  - meson
  - netcdf-c
  - netcdf-cxx
  - netcdf-fortran
  - ninja
  - openblas threads=openmp
  - osu-micro-benchmarks
  - papi
  - zlib-ng
  - nccl
  #- nccl-tests
  - cuda
  - cudnn
  - cutensor
  - cutlass +ipo
  - xcb-util-cursor
  - aws-ofi-nccl
  - superlu
  - nvshmem ~ucx +nccl +gdrcopy +libfabric
  - hydra
  - swig
  - libaio
  - faiss +python
  - python@3.12
  - python-venv
  - py-pip
  - py-cython
  - py-pybind11
  - py-numpy
  - py-torch@2.8.0 +cudnn +cusparselt +custom-protobuf +distributed +flash_attention +gloo +kineto +magma ~mkldnn +nccl +xnnpack +numpy +numa +openmp +qnnpack +tensorpipe +valgrind
  - py-torchaudio
  - py-torchvision
  - py-torchmetrics
  - py-triton +build-custom-llvm
  - py-transformers
  - py-einops
  - xtensor ~tbb +ipo
  - xtensor-python
  #- py-transformer-engine@main
  #- py-tensorboard
  #- py-tensorstore
  - py-vllm
  variants:
  - +mpi
  - +cuda
  - cuda_arch=90a
  views:
    default:
      link: all
      uenv:
        add_compilers: true
        prefix_paths:
          LD_LIBRARY_PATH: [lib, lib64]
